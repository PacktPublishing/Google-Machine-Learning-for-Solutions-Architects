{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "477267b4-755f-42da-9e47-ebd4f8dd7dc7",
   "metadata": {},
   "source": [
    "# Using pandas with BigQuery via pandas-gbq\n",
    "\n",
    "In this notebook, we explore how to use pandas with BigQuery via the pandas_gbq library.\n",
    "\n",
    "It's an open-source library that is maintained by PyData and volunteer contributors and has been around for quite some time (since 2017), so it has become quite broadly used in the industry.\n",
    "\n",
    "Essentially, itâ€™s a thin wrapper around the BigQuery client library (google-cloud-bigquery) that provides a simple interface for running SQL queries and uploading pandas dataframes to BigQuery. The results from these queries are parsed into a pandas.DataFrame object in which the shape and data types are derived from the source table.\n",
    "\n",
    "Let's dive in and start using it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7816bb5a-7266-49ea-90af-42c6cdf3257b",
   "metadata": {},
   "source": [
    "## Install and import libraries\n",
    "\n",
    "We start by installing and importing the required libraries (pandas, pandas_gbq, and numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b8313-4ed8-4962-b0b2-fd990d113f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --quiet pandas pandas-gbq numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dd596-48fa-4d57-af4a-6622317a28eb",
   "metadata": {},
   "source": [
    "### Restart the kernel\n",
    "\n",
    "After you install the additional packages, restart the notebook kernel so it can find the packages.",
    "\n",
    "Click OK when prompted after running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73f6a1-5b17-403a-b36f-9c809ba4bec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Restart kernel after installs\n",
    "import os\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aff328-bf53-4fb3-b838-3106f4fbd5b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# (Wait for the kernel to restart before continuing...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad4c67-baee-45c7-8f23-d82b202c79f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c282ab2-7818-4900-8ca4-c7e8802da040",
   "metadata": {},
   "source": [
    "## Define constants\n",
    "\n",
    "Next, we define the constants to contain our project ID and the dataset ID at which we will save our data in BigQuery later.\n",
    "\n",
    "**Replace \"YOUR_PROJECT_ID\" with your desired project ID.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35767946-dbbd-44de-885a-2a9946ffda43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"YOUR_PROJECT_ID\"\n",
    "UPDATED_DATASET_ID = \"new_york_taxi_trips.transformed_taxi_data_pandas_gbq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7f4ef-ddb5-4eeb-9881-3ca0c990d394",
   "metadata": {},
   "source": [
    "## Define and run the query to load our data\n",
    "\n",
    "In the next cell, we will run a simple SQL query to read in some data from the `New York Taxi Trips` BigQuery Public Dataset into a dataframe that we can then use in the remaining steps in this notebook. We will limit the number of records to 1000 because pandas_gbq will download the results of the query to our local environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f2063-3147-4cde-92ca-3bab11c838c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUERY = \"SELECT * FROM `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2020` LIMIT 1000\"\n",
    "\n",
    "# Use pandas-gbq to load the data into a DataFrame\n",
    "df = pandas_gbq.read_gbq(QUERY, project_id=\"still-sight-352221\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ddb3b9-cac0-40da-b43a-92f7bccce394",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "Now that we've read the data into a dataframe, we can begin to explore our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df5018b-7a00-4323-b830-c5dfc8006e82",
   "metadata": {},
   "source": [
    "### Preview the data\n",
    "\n",
    "Let's take a look at some of the values in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91678265-bc7d-4ec3-a13c-138ae57fd3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8cb17b-d796-4ae7-a19c-626db5b43197",
   "metadata": {},
   "source": [
    "### Explore the data types \n",
    "\n",
    "We can use the dtypes property to explore the data types in the fields of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39dff54-d209-4f38-83b3-54cbc4f54228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa76219-f20d-4330-b523-7cde40f3402c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summary statistics\n",
    "\n",
    "We can use the describe() function to display some summary statistics about the fields in our dataset. This can help us to understand the scale of features in our dataset, by displaying statistics such as `count`, `min`, `max`, `mean`, and the standard deviation (`std`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357ac70-81a2-410f-9d32-c3f07ddbb15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0cf78f-b6bc-4b8d-95ce-e8957cce5e0f",
   "metadata": {},
   "source": [
    "### Explore missing values\n",
    "\n",
    "Missing values can cause problems for many machine learning algorithms, so it's often important for data scientists to be aware of any missing values that exist in the dataset, and to address them accordingly. The code in the next cell will tell us how many missing values exist for each feature in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57668b1-de2a-444b-be29-2e3f2c829f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea6212-ae74-4164-a67c-c2228e7ff8bf",
   "metadata": {},
   "source": [
    "### Value counts\n",
    "\n",
    "It's also often important to understand how many unique values each feature contains. This is referred to as the `cardinality` of a feature, where low cardinality features have a small number of unique values (e.g., binary features that are either `yes` or `no`), and high cardinality have a large number of unique values (e.g., product IDs).\n",
    "\n",
    "Feature cardinality can be important to understand for tasks such as feature encoding and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2c08a-4cc2-4c64-b347-e7c4a14d813e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['passenger_count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad7278-c743-4a74-8444-66f33eb7f42f",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "After exploring our data, we can perform any feature engineering that we believe could be important for helping our models to learn specific patterns in our dataset.\n",
    "\n",
    "For example, we can engineer a new feature named `fare_per_mile` by diving the `fare_amount` feature by the `trip_distance` feature, and this new feature may be more useful if we want to build a model that estimates the fare for a given trip distance.\n",
    "\n",
    "To avoid errors such as type mismatches during our division operation, we will convert all types to float.\n",
    "To avoid division by zero, we replace all instances of zero in `trip_distance` with `numpy.finfo.eps` (epsilon), which is a tiny positive number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd2292-cb68-4138-b876-8daa9b0b5e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['fare_amount'] = df['fare_amount'].astype(float)\n",
    "df['trip_distance'] = df['trip_distance'].astype(float)\n",
    "df['fare_per_mile'] = df['fare_amount'] / df['trip_distance'].replace(0, np.finfo(float).eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6b1d3-43e2-4d20-ace7-ff37a7c81ed1",
   "metadata": {},
   "source": [
    "## Writing data to BigQuery\n",
    "\n",
    "After performing our feature engineering steps, we can write our updated data back to BigQuery for long term storage, reference, and analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84583705-103e-437e-ac39-210c4abe8450",
   "metadata": {},
   "source": [
    "### Convert decimal types to float\n",
    "\n",
    "The following is a step that only appears to be necessary when using `pandas_gbq` to write this specific dataset to BigQuery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c245e9-c38b-4fc3-be58-7b8c3837c880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert all columns of type 'decimal.Decimal' to 'float'\n",
    "for column in df.columns:\n",
    "    if pd.api.types.is_object_dtype(df[column]):\n",
    "        try:\n",
    "            df[column] = df[column].astype(float)\n",
    "        except (ValueError, TypeError):\n",
    "            pass  # or handle non-convertible columns as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480cd67-025b-4d12-8e11-78fe15962556",
   "metadata": {},
   "source": [
    "### Write the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae49a80-4304-4512-bacb-789c5caf3dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_gbq(f\"{PROJECT_ID}.{UPDATED_DATASET_ID}\") "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
